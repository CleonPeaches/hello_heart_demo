{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c68ee67a-1a44-489e-8580-4eb135579283",
   "metadata": {},
   "source": [
    "## Step 1: Data Ingestion\n",
    "Ingest data from the two provided CSV files. One contains patient details, and the other contains appointment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6f2e17-75d6-4844-8e9a-42912de0bb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of appointments: 1000\n",
      "Number of patients: 1000\n",
      "\n",
      "Sample Appointments:\n",
      "+----------+----------------+--------------+\n",
      "|patient_id|appointment_date|doctor        |\n",
      "+----------+----------------+--------------+\n",
      "|236       |2024-05-17      |Morgan Baker  |\n",
      "|225       |2024-08-03      |Vincent Wright|\n",
      "|831       |2024-07-19      |Joshua Ford   |\n",
      "|116       |2024-03-02      |Michelle Hill |\n",
      "|433       |2024-01-17      |Kari Morse    |\n",
      "+----------+----------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Sample Patients:\n",
      "+----------+-----------------+---+-------------------------------------------------------+---------------------+-------------+\n",
      "|patient_id|name             |age|address                                                |phone_number         |diagnosis    |\n",
      "+----------+-----------------+---+-------------------------------------------------------+---------------------+-------------+\n",
      "|1         |Nicole Taylor    |36 |6377 Jennifer Trail Apt. 075, Calebside, NY 22906      |080.898.3247         |Asthma       |\n",
      "|2         |Nathan Dorsey    |46 |056 Thompson Park Suite 212, West Anitaport, NY 11534  |001-282-603-2670x455 |Asthma       |\n",
      "|3         |Jennifer Garcia  |61 |792 Mark Wells, Jaclynport, TN 90027                   |861-464-2617x287     |Diabetes     |\n",
      "|4         |Joshua Simon     |41 |05655 Harris Inlet, Nealton, MS 89986                  |531-269-0179         |Asthma       |\n",
      "|5         |Juan Gallegos    |37 |150 Miranda Unions, Bradburgh, FL 64440                |+1-771-958-5462x30717|Asthma       |\n",
      "|6         |Dawn Holland     |39 |2523 Flores Radial Suite 462, South Hannah, ND 92740   |+1-134-564-3940x037  |None         |\n",
      "|7         |Alan Garrison    |79 |3040 Eddie Bypass, Lake Andrew, RI 07138               |001-582-878-8103x560 |Diabetes     |\n",
      "|8         |Zachary Wilson   |31 |USNS Thompson, FPO AP 63179                            |5687121605           |Hypertension |\n",
      "|9         |Rhonda Oconnor   |27 |184 Soto Pines Apt. 875, West Dakota, GA 96278         |275.444.2526         |Asthma       |\n",
      "|10        |Leslie Baker     |55 |0476 Jake Locks Suite 921, Lewishaven, MT 10958        |001-172-091-9421x7978|Hypertension |\n",
      "|11        |Marissa Carlson  |35 |18331 Mendez Pike, Reidhaven, GA 29116                 |(142)411-2096x8020   |Hypertension |\n",
      "|12        |Natalie Espinoza |25 |56674 Edwards Divide Apt. 010, Kimland, MS 78734       |001-903-137-6800x8908|Hypertension |\n",
      "|13        |Thomas Lewis     |69 |2972 Erika Rapid, Knightborough, AK 93261              |297.042.4749         |Hypertension |\n",
      "|14        |Jamie Patton     |39 |5790 Gregory Ville Suite 343, Lake Ryanland, NJ 30897  |736.521.3499x896     |Hypertension |\n",
      "|15        |Ryan Jacobs      |54 |968 Christopher Fields Suite 713, Bradleyside, MI 11292|+1-465-777-3427x928  |Heart Disease|\n",
      "|16        |Edward Spencer   |58 |91342 Lambert Bridge Apt. 578, Allentown, AZ 29340     |518-999-4027         |Diabetes     |\n",
      "|17        |Nicholas Lynn    |18 |326 Kimberly Pines, Charleschester, GA 05194           |+1-479-155-5838x704  |Diabetes     |\n",
      "|18        |Shane Johnson    |35 |96692 Joseph Plains, Lake Alexander, NV 13222          |+1-261-162-5054x658  |Asthma       |\n",
      "|19        |Heather Maldonado|28 |878 Anna Meadows Suite 965, Johnland, SD 96413         |0427516494           |Heart Disease|\n",
      "|20        |Kimberly Sutton  |36 |4167 Gilbert Loaf, Lake Traceyville, MA 28891          |863.728.9008x8855    |Asthma       |\n",
      "|21        |Kelly Sanchez    |69 |285 Ho Meadows, Davidburgh, LA 22803                   |(482)525-8195x02966  |Diabetes     |\n",
      "|22        |Lauren Brown     |41 |092 Miller Shore, Rachelland, NM 38042                 |215.426.2649x5099    |Asthma       |\n",
      "|23        |Luis Lambert     |23 |192 Cheryl Court Apt. 188, North Connie, OR 31404      |707-689-2739x37123   |Diabetes     |\n",
      "|24        |Jennifer Lin     |41 |9786 Sandy Roads Suite 017, Heatherstad, MN 65581      |069-010-8837         |None         |\n",
      "|25        |Stephanie Lin    |37 |581 Tricia Walk Suite 688, Port Loretta, MI 29281      |192.542.1112         |None         |\n",
      "+----------+-----------------+---+-------------------------------------------------------+---------------------+-------------+\n",
      "only showing top 25 rows\n",
      "\n",
      "+-------------------------------------------------------+\n",
      "|address                                                |\n",
      "+-------------------------------------------------------+\n",
      "|6377 Jennifer Trail Apt. 075, Calebside, NY 22906      |\n",
      "|056 Thompson Park Suite 212, West Anitaport, NY 11534  |\n",
      "|792 Mark Wells, Jaclynport, TN 90027                   |\n",
      "|05655 Harris Inlet, Nealton, MS 89986                  |\n",
      "|150 Miranda Unions, Bradburgh, FL 64440                |\n",
      "|2523 Flores Radial Suite 462, South Hannah, ND 92740   |\n",
      "|3040 Eddie Bypass, Lake Andrew, RI 07138               |\n",
      "|USNS Thompson, FPO AP 63179                            |\n",
      "|184 Soto Pines Apt. 875, West Dakota, GA 96278         |\n",
      "|0476 Jake Locks Suite 921, Lewishaven, MT 10958        |\n",
      "|18331 Mendez Pike, Reidhaven, GA 29116                 |\n",
      "|56674 Edwards Divide Apt. 010, Kimland, MS 78734       |\n",
      "|2972 Erika Rapid, Knightborough, AK 93261              |\n",
      "|5790 Gregory Ville Suite 343, Lake Ryanland, NJ 30897  |\n",
      "|968 Christopher Fields Suite 713, Bradleyside, MI 11292|\n",
      "|91342 Lambert Bridge Apt. 578, Allentown, AZ 29340     |\n",
      "|326 Kimberly Pines, Charleschester, GA 05194           |\n",
      "|96692 Joseph Plains, Lake Alexander, NV 13222          |\n",
      "|878 Anna Meadows Suite 965, Johnland, SD 96413         |\n",
      "|4167 Gilbert Loaf, Lake Traceyville, MA 28891          |\n",
      "|285 Ho Meadows, Davidburgh, LA 22803                   |\n",
      "|092 Miller Shore, Rachelland, NM 38042                 |\n",
      "|192 Cheryl Court Apt. 188, North Connie, OR 31404      |\n",
      "|9786 Sandy Roads Suite 017, Heatherstad, MN 65581      |\n",
      "|581 Tricia Walk Suite 688, Port Loretta, MI 29281      |\n",
      "|504 Terrell River Apt. 416, Coleview, OK 03154         |\n",
      "|USNS Lowe, FPO AP 93039                                |\n",
      "|02040 Jonathan Forest Suite 483, Shawshire, MO 69926   |\n",
      "|3425 Kelly Knoll, North Brandon, RI 87775              |\n",
      "|33582 Holly Overpass Apt. 076, Sharonshire, MS 29668   |\n",
      "|12778 Anna Drive, North Barbara, OH 79071              |\n",
      "|117 Amanda Ranch, Beckerfurt, ND 11340                 |\n",
      "|Unit 1087 Box 5462, DPO AA 57006                       |\n",
      "|34079 Carmen Rapid, Shieldsport, SC 27003              |\n",
      "|0465 Rose Meadows, Sethburgh, NE 03639                 |\n",
      "|68911 Walter Mountain, North Gabrielle, DE 84569       |\n",
      "|USCGC Murray, FPO AA 80530                             |\n",
      "|113 Nicolas Isle, West Williamland, NV 85966           |\n",
      "|9799 Gates Place, Jamesshire, GA 87280                 |\n",
      "|7885 Garcia Alley Suite 064, Flynnton, SD 92390        |\n",
      "|584 Jonathan Radial, New Monicaland, ND 80986          |\n",
      "|479 Judy Walks Apt. 256, Jenniferside, DC 04483        |\n",
      "|1692 Stephen Bridge, New Gregory, IN 94855             |\n",
      "|5150 Thomas Court, Isaacbury, WI 34094                 |\n",
      "|52761 Jamie Fields, Reynoldshaven, MN 03951            |\n",
      "|7535 Woods Courts, Katieview, WI 11426                 |\n",
      "|9936 Hanson Dam, New Lisaside, TX 77908                |\n",
      "|8890 Brian Vista, Lake Seanview, CT 14513              |\n",
      "|269 Cory Hills Apt. 071, Lake Ashley, GA 61006         |\n",
      "|3222 David Land Apt. 889, West Andreatown, NM 40602    |\n",
      "+-------------------------------------------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "try:\n",
    "    # Create Spark session\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"hello_heart_data\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    # Read the CSV files\n",
    "    appointments_df = spark.read.csv('sample_data/appointment_data.csv', header=True, inferSchema=True)\n",
    "    patients_df = spark.read.csv('sample_data/patient_data.csv', header=True, inferSchema=True)\n",
    "    \n",
    "    # Get row counts\n",
    "    print(f\"\\nNumber of appointments: {appointments_df.count()}\")\n",
    "    print(f\"Number of patients: {patients_df.count()}\")\n",
    "    \n",
    "    print(\"\\nSample Appointments:\")\n",
    "    appointments_df.show(5, truncate=False)\n",
    "    \n",
    "    print(\"\\nSample Patients:\")\n",
    "    patients_df.show(25, truncate=False)\n",
    "    patients_df.select(\"address\").show(50, truncate=False)\n",
    "except Exception as e:\n",
    "    raise Exception(\"Error while loading files into dataframes: \", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a486f51b-a23e-457b-8126-05c917c67a6e",
   "metadata": {},
   "source": [
    "## Step 1a: Capture schemas and save them to a schema file\n",
    "Load the original schemas as json files into file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00a466e3-0652-44a2-a14f-ced14211fc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schemas saved successfully.\n",
      "\n",
      "Appointments Schema:\n",
      "struct<patient_id:int,appointment_date:date,doctor:string>\n",
      "\n",
      "Patients Schema:\n",
      "struct<patient_id:int,name:string,age:int,address:string,phone_number:string,diagnosis:string>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Capture schemas\n",
    "    appointments_schema = appointments_df.schema\n",
    "    patients_schema = patients_df.schema\n",
    "    \n",
    "    # Save schemas as JSON files\n",
    "    with open('schemas/appointments_schema.json', 'w') as f:\n",
    "        f.write(appointments_schema.json())\n",
    "    with open('schemas/patients_schema.json', 'w') as f:\n",
    "        f.write(patients_schema.json())\n",
    "    \n",
    "    print(\"Schemas saved successfully.\")\n",
    "    \n",
    "    # Print schemas for reference\n",
    "    print(\"\\nAppointments Schema:\")\n",
    "    print(appointments_schema.simpleString())\n",
    "    \n",
    "    print(\"\\nPatients Schema:\")\n",
    "    print(patients_schema.simpleString())\n",
    "except Exception as e:\n",
    "    raise Exception(\"Error while capturing schemas: \", str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00429544-be88-44f2-abca-115c9b7ef71a",
   "metadata": {},
   "source": [
    "## Step 1b: Load new schema and compare it with the old one\n",
    "If there's a change, check if it's a column addition, rename, or deletion.\n",
    "- Addition: attempt to add the column\n",
    "- Deletion or rename: raise an exception and send alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5a6d212-3a7d-4177-8a46-91f346061838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No schema changes detected for Patients.\n",
      "Number of updated patients: 1000\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType\n",
    "import json\n",
    "\n",
    "def compare_and_update_schema(existing_schema_path, new_schema, schema_name):\n",
    "    # Load the existing schema\n",
    "    with open(existing_schema_path, 'r') as f:\n",
    "        existing_schema = StructType.fromJson(json.loads(f.read()))\n",
    "    \n",
    "    # Extract column names\n",
    "    existing_columns = set(field.name for field in existing_schema.fields)\n",
    "    new_columns = set(field.name for field in new_schema.fields)\n",
    "    \n",
    "    # Identify changes\n",
    "    added_columns = new_columns - existing_columns\n",
    "    removed_columns = existing_columns - new_columns\n",
    "    \n",
    "    # Handle schema changes\n",
    "    if removed_columns:\n",
    "        raise Exception(f\"Schema change detected in {schema_name}: Columns removed: {removed_columns}\")\n",
    "    elif added_columns:\n",
    "        print(f\"Schema change detected in {schema_name}: Columns added: {added_columns}\")\n",
    "        # Update the schema to include new columns\n",
    "        updated_schema = StructType(existing_schema.fields + \n",
    "                                    [field for field in new_schema.fields if field.name in added_columns])\n",
    "        # Save the updated schema\n",
    "        with open(existing_schema_path, 'w') as f:\n",
    "            f.write(updated_schema.json())\n",
    "        print(f\"Schema updated successfully for {schema_name}.\")\n",
    "    else:\n",
    "        print(f\"No schema changes detected for {schema_name}.\")\n",
    "        \n",
    "    return existing_schema\n",
    "\n",
    "try:\n",
    "    # Read a new file with updated schema\n",
    "    patients_df = spark.read.csv('sample_data/patient_data_updated.csv', header=True, inferSchema=True)\n",
    "    \n",
    "    # Compare and update schemas\n",
    "    compare_and_update_schema('schemas/patients_schema.json', patients_df.schema, \"Patients\")\n",
    "    \n",
    "    # Continue with data processing\n",
    "    print(f\"Number of updated patients: {patients_df.count()}\")\n",
    "except Exception as e:\n",
    "    raise Exception(\"Error: \", str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dcaf97-fab7-4a54-90a6-7ab6f64cee27",
   "metadata": {},
   "source": [
    "## Step 2: Data Transformation (Should occur before de-identification)\n",
    "Clean and transform the data. Ensure that:\n",
    "- Phone numbers and addresses are in a consistent format.\n",
    "- Data is deduplicated based on patient_id.\n",
    "- Join the two datasets using patient_id to create a single view of the patient and their appointment history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c550fb51-e1f6-4470-9132-fb2b0d4a386d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------+\n",
      "|address                                              |\n",
      "+-----------------------------------------------------+\n",
      "|6377 Jennifer Trl Apt 1, Calebside, NY 22906         |\n",
      "|1 Thompson Park Ste 212, West Anitaport, NY 11534    |\n",
      "|792 Mark Wells, Jaclynport, TN 90027                 |\n",
      "|1 Harris Inlet, Nealton, MS 89986                    |\n",
      "|150 Miranda Unions, Bradburgh, FL 64440              |\n",
      "|2523 Flores Radial Ste 462, South Hannah, ND 92740   |\n",
      "|3040 Eddie Byp, Lake Andrew, RI 07138                |\n",
      "|USNS Thompson, FPO AP 63179                          |\n",
      "|184 Soto Pines Apt 875, West Dakota, GA 96278        |\n",
      "|1 Jake Locks Ste 921, Lewishaven, MT 10958           |\n",
      "|18331 Mendez Pike, Reidhaven, GA 29116               |\n",
      "|56674 Edwards Divide Apt 1, Kimland, MS 78734        |\n",
      "|2972 Erika Rapid, Knightborough, AK 93261            |\n",
      "|5790 Gregory Ville Ste 343, Lake Ryanland, NJ 30897  |\n",
      "|968 Christopher Fields Ste 713, Bradleyside, MI 11292|\n",
      "|91342 Lambert Bridge Apt 578, Allentown, AZ 29340    |\n",
      "|326 Kimberly Pines, Charleschester, GA 05194         |\n",
      "|96692 Joseph Plains, Lake Alexander, NV 13222        |\n",
      "|878 Anna Meadows Ste 965, Johnland, SD 96413         |\n",
      "|4167 Gilbert Loaf, Lake Traceyville, MA 28891        |\n",
      "|285 Ho Meadows, Davidburgh, LA 22803                 |\n",
      "|1 Miller Shore, Rachelland, NM 38042                 |\n",
      "|192 Cheryl Ct Apt 188, North Connie, OR 31404        |\n",
      "|9786 Sandy Roads Ste 1, Heatherstad, MN 65581        |\n",
      "|581 Tricia Walk Ste 688, Port Loretta, MI 29281      |\n",
      "|504 Terrell River Apt 416, Coleview, OK 03154        |\n",
      "|USNS Lowe, FPO AP 93039                              |\n",
      "|1 Jonathan Forest Ste 483, Shawshire, MO 69926       |\n",
      "|3425 Kelly Knoll, North Brandon, RI 87775            |\n",
      "|33582 Holly Overpass Apt 1, Sharonshire, MS 29668    |\n",
      "|12778 Anna Drive, North Barbara, OH 79071            |\n",
      "|117 Amanda Ranch, Beckerfurt, ND 11340               |\n",
      "|Unit 1087 Box 5462, DPO AA 57006                     |\n",
      "|34079 Carmen Rapid, Shieldsport, SC 27003            |\n",
      "|1 Rose Meadows, Sethburgh, NE 03639                  |\n",
      "|68911 Walter Mountain, North Gabrielle, DE 84569     |\n",
      "|USCGC Murray, FPO AA 80530                           |\n",
      "|113 Nicolas Isle, West Williamland, NV 85966         |\n",
      "|9799 Gates Place, Jamesshire, GA 87280               |\n",
      "|7885 Garcia Alley Ste 1, Flynnton, SD 92390          |\n",
      "|584 Jonathan Radial, New Monicaland, ND 80986        |\n",
      "|479 Judy Walks Apt 256, Jenniferside, DC 04483       |\n",
      "|1692 Stephen Bridge, New Gregory, IN 94855           |\n",
      "|5150 Thomas Ct, Isaacbury, WI 34094                  |\n",
      "|52761 Jamie Fields, Reynoldshaven, MN 03951          |\n",
      "|7535 Woods Courts, Katieview, WI 11426               |\n",
      "|9936 Hanson Dam, New Lisaside, TX 77908              |\n",
      "|8890 Brian Vista, Lake Seanview, CT 14513            |\n",
      "|269 Cory Hills Apt 1, Lake Ashley, GA 61006          |\n",
      "|3222 David Land Apt 889, West Andreatown, NM 40602   |\n",
      "|34855 Moody Streets, East Donald, SD 93697           |\n",
      "|26337 Kim Islands Apt 550, Port Henryview, TN 65039  |\n",
      "|4908 Gray Prairie Ste 1, Robertburgh, NH 01356       |\n",
      "|PSC 9145, Box 0163, APO AA 81756                     |\n",
      "|6756 Delacruz Divide, Yvetteside, OR 03987           |\n",
      "|PSC 1743, Box 0934, APO AE 19008                     |\n",
      "|1 Crawford Mountains Apt 897, Pettyside, AK 10881    |\n",
      "|335 Bauer Junction Ste 491, Burtonbury, WA 80207     |\n",
      "|Unit 8030 Box 5685, DPO AA 78871                     |\n",
      "|86575 Ramos Hills, North Jennifershire, MS 23877     |\n",
      "|6838 Nicole Common, East Andrew, TN 73320            |\n",
      "|5764 Ford Pike, South Daniel, MO 47421               |\n",
      "|651 Smith Field, Lopezside, TX 61327                 |\n",
      "|91542 Dylan Vista, West Amandafurt, AZ 59672         |\n",
      "|2456 Karen Extensions, South Derrick, TX 89009       |\n",
      "|79542 Jordan Alley, Robertborough, MT 50255          |\n",
      "|88945 Marvin Extension, Randyport, MT 52060          |\n",
      "|30748 David Estates, North Grace, FL 22366           |\n",
      "|196 Kristina Roads Ste 878, Port Teresastad, MN 28483|\n",
      "|296 Meyer Springs Apt 778, Brookeport, MT 86355      |\n",
      "|16566 Megan Spur Apt 399, New Tiffanyfurt, NH 63961  |\n",
      "|4121 Steven Ridge, Sparksborough, CT 49404           |\n",
      "|345 Tracie Pass Ste 930, Bookertown, WY 60685        |\n",
      "|PSC 2745, Box 0008, APO AP 23603                     |\n",
      "|PSC 1235, Box 5272, APO AA 44157                     |\n",
      "|20535 Troy Ridge, Jeffborough, MS 74541              |\n",
      "|9920 Fletcher Viaduct Ste 761, Richardland, GA 98177 |\n",
      "|USNV Ewing, FPO AE 72023                             |\n",
      "|PSC 3171, Box 0485, APO AE 73953                     |\n",
      "|91777 Brian Summit Apt 837, Port Evanside, VT 68753  |\n",
      "|PSC 1088, Box 3965, APO AA 54706                     |\n",
      "|8568 Jackson Curve, Whiteberg, IL 34324              |\n",
      "|263 Daniel Ways Apt 206, Markborough, OK 43107       |\n",
      "|68077 Werner Drive, Barronport, RI 08792             |\n",
      "|361 Simpson Mountain, Elizabethside, WY 53728        |\n",
      "|1 Victor Run Apt 734, South Benjaminberg, TN 31606   |\n",
      "|1 Shannon Dam, Bonillaburgh, MO 18462                |\n",
      "|75172 Wilson Route, Thomaston, NJ 74772              |\n",
      "|PSC 4529, Box 5655, APO AA 91250                     |\n",
      "|8182 Keith Forges Ste 930, East Darlene, VA 21592    |\n",
      "|7235 Alex Mount Ste 324, New Cody, AZ 78561          |\n",
      "|88852 Ashley Station, North Andrew, KY 85444         |\n",
      "|Unit 6564 Box 7246, DPO AE 30985                     |\n",
      "|560 Martin Point Ste 132, Davidmouth, WY 70079       |\n",
      "|5860 Frederick Terrace Ste 279, Kevinview, MS 86451  |\n",
      "|7141 Johnson Oval, Lake Jenniferhaven, CT 47312      |\n",
      "|437 Theodore Port Apt 197, New Theodore, MS 27984    |\n",
      "|44246 Estrada Ramp Apt 1, Amandahaven, IL 18467      |\n",
      "|1 Brian Grove, Port Lindseystad, CT 44703            |\n",
      "|47181 Jones Burg, Nicoleberg, VT 64208               |\n",
      "+-----------------------------------------------------+\n",
      "only showing top 100 rows\n",
      "\n",
      "+----------------+-------------------+\n",
      "|total_patient_id|distinct_patient_id|\n",
      "+----------------+-------------------+\n",
      "|            1000|               1000|\n",
      "+----------------+-------------------+\n",
      "\n",
      "+----------+----------------+---+--------------------------------------------------+----------------+------------+-------------------+----------------+------------------+\n",
      "|patient_id|name            |age|address                                           |phone_number    |diagnosis   |email              |appointment_date|doctor            |\n",
      "+----------+----------------+---+--------------------------------------------------+----------------+------------+-------------------+----------------+------------------+\n",
      "|3         |Jennifer Garcia |61 |792 Mark Wells, Jaclynport, TN 90027              |8614642617x287  |Diabetes    |testemail@gmail.com|2024-05-12      |Kristina Collins  |\n",
      "|4         |Joshua Simon    |41 |1 Harris Inlet, Nealton, MS 89986                 |5312690179      |Asthma      |testemail@gmail.com|2024-08-17      |Felicia Moore     |\n",
      "|5         |Juan Gallegos   |37 |150 Miranda Unions, Bradburgh, FL 64440           |7719585462x30717|Asthma      |testemail@gmail.com|2024-05-08      |Jason Taylor      |\n",
      "|5         |Juan Gallegos   |37 |150 Miranda Unions, Bradburgh, FL 64440           |7719585462x30717|Asthma      |testemail@gmail.com|2024-03-20      |Eugene Wilson MD  |\n",
      "|6         |Dawn Holland    |39 |2523 Flores Radial Ste 462, South Hannah, ND 92740|1345643940x037  |None        |testemail@gmail.com|2024-08-23      |Jessica Martin    |\n",
      "|8         |Zachary Wilson  |31 |USNS Thompson, FPO AP 63179                       |5687121605      |Hypertension|testemail@gmail.com|2024-01-18      |Erin Castro       |\n",
      "|10        |Leslie Baker    |55 |1 Jake Locks Ste 921, Lewishaven, MT 10958        |1720919421x7978 |Hypertension|testemail@gmail.com|2024-09-08      |Mary Ortiz        |\n",
      "|11        |Marissa Carlson |35 |18331 Mendez Pike, Reidhaven, GA 29116            |1424112096x8020 |Hypertension|testemail@gmail.com|2024-04-17      |Sherri Fitzpatrick|\n",
      "|12        |Natalie Espinoza|25 |56674 Edwards Divide Apt 1, Kimland, MS 78734     |9031376800x8908 |Hypertension|testemail@gmail.com|2024-07-04      |Joy Price         |\n",
      "|12        |Natalie Espinoza|25 |56674 Edwards Divide Apt 1, Kimland, MS 78734     |9031376800x8908 |Hypertension|testemail@gmail.com|2024-01-03      |Richard Martinez  |\n",
      "+----------+----------------+---+--------------------------------------------------+----------------+------------+-------------------+----------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Problems with patients data:\n",
    "    - Phone number\n",
    "        - Inconsistent use of country code\n",
    "        - Inconsistent use of extension\n",
    "        - Inconsistent format of country code (001 and +1)\n",
    "        - Inconsistent use of spaces, dots, dashes, and parenthesis\n",
    "    - Address \n",
    "        - Leading zeroes on house, apartment, and suite number which should be stripped\n",
    "        - Leading zeroes on box number and zip code which should be preserved\n",
    "        - Common words like Cicle and Apartment may already be abbreviated, abbreviate just in case\n",
    "'''\n",
    "\n",
    "from pyspark.sql.functions import regexp_replace, concat_ws, col, when, split, length, count, countDistinct, trim\n",
    "\n",
    "try:\n",
    "    # Clean the original column to remove non-numeric characters\n",
    "    patients_df = patients_df.withColumn(\"phone_number\", regexp_replace(col(\"phone_number\"), r\"[^0-9x]\", \"\"))\n",
    "    \n",
    "    # Split phone_number into core_number and extension\n",
    "    split_col = split(col(\"phone_number\"), \"x\")\n",
    "    patients_df = patients_df.withColumn(\"core_number\", split_col.getItem(0)) \\\n",
    "                             .withColumn(\"extension\", split_col.getItem(1))\n",
    "    \n",
    "    # Strip country code based on the length of core_number\n",
    "    patients_df = patients_df.withColumn(\n",
    "        \"core_number\",\n",
    "        when((length(col(\"core_number\")) == 11), col(\"core_number\").substr(2, 10))\n",
    "        .when((length(col(\"core_number\")) == 12), col(\"core_number\").substr(3, 10))\n",
    "        .when((length(col(\"core_number\")) == 13), col(\"core_number\").substr(4, 10))\n",
    "        .otherwise(col(\"core_number\"))\n",
    "    )\n",
    "    \n",
    "    # Recombine core phone number and extension\n",
    "    patients_df = patients_df.withColumn(\n",
    "        \"phone_number\",\n",
    "        when(col(\"extension\") != \"\", concat_ws(\"x\", col(\"core_number\"), col(\"extension\")))\n",
    "        .otherwise(col(\"core_number\"))\n",
    "    )\n",
    "    \n",
    "    # Drop intermediary columns\n",
    "    patients_df = patients_df.drop(\"core_number\", \"extension\")\n",
    "    \n",
    "    # Normalize addresses\n",
    "    patients_df = patients_df \\\n",
    "        .withColumn(\"address\", trim(col(\"address\"))) \\\n",
    "        .withColumn(\"address\", regexp_replace(col(\"address\"), r\"\\.\", \"\")) \\\n",
    "        .withColumn(\"address\", regexp_replace(col(\"address\"), r\"\\bApartment\\b\", \"Apt\")) \\\n",
    "        .withColumn(\"address\", regexp_replace(col(\"address\"), r\"\\bStreet\\b\", \"St\")) \\\n",
    "        .withColumn(\"address\", regexp_replace(col(\"address\"), r\"\\bCircle\\b\", \"Cir\")) \\\n",
    "        .withColumn(\"address\", regexp_replace(col(\"address\"), r\"\\bCourt\\b\", \"Ct\")) \\\n",
    "        .withColumn(\"address\", regexp_replace(col(\"address\"), r\"\\bSuite\\b\", \"Ste\")) \\\n",
    "        .withColumn(\"address\", regexp_replace(col(\"address\"), r\"\\bTrail\\b\", \"Trl\")) \\\n",
    "        .withColumn(\"address\", regexp_replace(col(\"address\"), r\"\\bBypass\\b\", \"Byp\")) \\\n",
    "        .withColumn(\"address\", regexp_replace(col(\"address\"), r\",\", \", \")) \\\n",
    "        .withColumn(\"address\", regexp_replace(col(\"address\"), r\"\\s+\", \" \")) \\\n",
    "        .withColumn(\"address\", regexp_replace(col(\"address\"), r\"(?<=^|\\sApt\\s|\\sSte\\s)0+(\\d+)\", r\"\\1\"))\n",
    "    \n",
    "    \n",
    "    # Show normalized df\n",
    "    patients_df.select(\"address\").show(100, truncate=False)\n",
    "    \n",
    "    # No duplicates found in this file, but dupes could be found in future files.\n",
    "    patients_df.select(\n",
    "        count(\"patient_id\").alias(\"total_patient_id\"),\n",
    "        countDistinct(\"patient_id\").alias(\"distinct_patient_id\")\n",
    "    ).show()\n",
    "    \n",
    "    # Drop duplicates based on patient_id\n",
    "    patients_df = patients_df.dropDuplicates([\"patient_id\"])\n",
    "    \n",
    "    # Join patients to appointments and create a view\n",
    "    appointment_history_df = patients_df.join(appointments_df, on=\"patient_id\", how=\"inner\")\n",
    "    appointment_history_df.createOrReplaceTempView(\"appointment_history\")\n",
    "    appointment_history_df.show(10, truncate=False)\n",
    "except Exception as e:\n",
    "    raise Exception(\"Error while normalizing and deduplicating dataframes: \", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8655fddb-6b5e-4d64-8c68-e700f4244c5f",
   "metadata": {},
   "source": [
    "## Step 3: De-identification (Should occur after transformation)\n",
    "De-identify sensitive patient data such as name, address, and phone_number using an anonymization technique (e.g., hashing).\n",
    "Ensure that the data can still be linked across the two datasets via a secure common identifier (e.g., patient_id)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7184ef73-63e9-4878-902f-b72ed10d0cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of anonymized patients:\n",
      "+----------+----------------------------------------------------------------+---+----------------------------------------------------------------+----------------------------------------------------------------+------------+----------------------------------------------------------------+----------------+------------------+\n",
      "|patient_id|name                                                            |age|address                                                         |phone_number                                                    |diagnosis   |email                                                           |appointment_date|doctor            |\n",
      "+----------+----------------------------------------------------------------+---+----------------------------------------------------------------+----------------------------------------------------------------+------------+----------------------------------------------------------------+----------------+------------------+\n",
      "|3         |edbbec22d143c17faa6d1fbc126848d5f3c2af1891b49e6e5a89856e94a75073|61 |f8232328103cd42ebe67c1ea4792eab69248ea86aa314e3da94e29cc7dfa6fae|fd639f173113f6c503f8ad309b13a058f08726c9e68b88d3cc1e12d3aeb736d4|Diabetes    |c65d1ed349bf2e0d8e1ea1736d7321727431ff62e531da8bd4f7ecc1d26166da|2024-05-12      |Kristina Collins  |\n",
      "|4         |bf52e5364a364ad00d4ecabec3b412920ea2c5400953b124b487a092c25ff254|41 |84e86b71deeca69100ef2825fef46212db10c57750d42654d04561dd05a606a6|2a6d4d79f08bd453f6e48d972ef6997089cd2225e7ff188ac169e70446848bf7|Asthma      |3e49fc8f0993837fd50f3623d82aa98729a4135cba8ce3340a8e90588e89cb61|2024-08-17      |Felicia Moore     |\n",
      "|5         |c0fb9db225cf1f60caf9dfe5eeeb43ee2084d2d6d81eb382e04ef29d71839fe9|37 |68aea7eddb08b800275e25c73393ad6c00466d30c11141bb000ac3eb71bd039d|787413c976b5e40a02cb17597e925966300534e89e978cee1c4a8ee39c565e2b|Asthma      |25c4ee61b413f23d46be49ea6d506907fab1af5d97bfb9637327517369ead6f4|2024-05-08      |Jason Taylor      |\n",
      "|5         |dde950159416aab1744c079532f218e89e5bfc997760fd7d686d03f79ef46232|37 |ae851dd4c557014a660d5c0c24774a48150c4de33f1f7d7cd8c6f8bb1244504a|899921ebb083f4ca2b42984a105c647ad83a867dfb359a4f3b0cb43044675692|Asthma      |c0f9488a4749aadcf4971bdc96ff34a4aa02518f2e330748d89dd641dcf225e4|2024-03-20      |Eugene Wilson MD  |\n",
      "|6         |ee447981499c5e5bd8d33cc4ee4a49d4b6a5d25622c7661b6da2981f30ef87af|39 |f9b9e460180f4fe0800ace4df8bfcd78f50fe531caa448a413292cd46b9a7018|863b86640cc646353485911b7f8180d4aa6ec1a6d29f418efc1c41d9a05a01b7|None        |21024f07b5f5fd256f95eaf107ea471459be4adca87c4b62be2d98d35eeefa87|2024-08-23      |Jessica Martin    |\n",
      "|8         |a95af130d97bf9ad1aad4046066374b1eca287b0c50a4eb47c06f2ad42ff63b8|31 |7329b896e4a289a9529592fb0847580a46ca516d7e3ac38af929926ec71b56d4|deced80c30a8c28116df40098c1816bc7d38ed1586b21088437a0d8a5ab65926|Hypertension|2d4863e58e019fb4e89670c4c8d7a2524467579f5113fb62e5268824e5b56d67|2024-01-18      |Erin Castro       |\n",
      "|10        |0f0d9994095bb8351a950772604c7e05e6dde9d02a8c477f3ae4d65433f6e847|55 |84df26fc1f1b6d3e292632e969314870c4dbc8a794e670ee72cce34e2cbfc801|2074f0023ab45ef2ae2240fdbf65ed52a4b10794dc739952adbe97ed3bef70ba|Hypertension|0bb7521bca0cca37d2aa948a35a0d31bf5d67952d83331aeb80049731c44853d|2024-09-08      |Mary Ortiz        |\n",
      "|11        |6b9612f2f6609cca3dcab4f38dcfadc69715b667ed61e92ac8ec4237b19d2c02|35 |015132f1d8eb9b13d963868c1c098f373431350c75faa94f9f78b2a9d9d139a2|73fe24305636ba5d5f60ea6cd8a337ab91ea5014aada259c3f97a79926458cae|Hypertension|9bf3b33cd1626082f99a6b6914e7c0e648c721c7c0e203eaabc3638a5e878a2a|2024-04-17      |Sherri Fitzpatrick|\n",
      "|12        |4e99af056eaca00d6b381f46dd96edba71c22cfff76f1f7db92bd4aaefa2f4a6|25 |9a05ca99c0b9e0f4054f6718e1d002452137a972809286e257a9abc01a218d23|003314fa08e36f41a729869f830ee0228f112034237a3b02cb6ea9a3ea1c047b|Hypertension|8349454cc72af21ebc967ac47ab3508c25e6eaa84ed7e25366800b2a832aa243|2024-07-04      |Joy Price         |\n",
      "|12        |0903a2d2172c4fa8510fadf85e5e204584888b9504ac95f31b5a0502efd1ac61|25 |fcc58089c11d7ed714cad0ea811eb9b24787871c67a41b1e337189c858a01be0|f6121a092c69de3decf58fa798558b73ab5a9ec174ec21e57dd9c4166b4103f6|Hypertension|32de985080b15fb470c0f9fc48125968c240613eea99bab35ca58a159249e668|2024-01-03      |Richard Martinez  |\n",
      "+----------+----------------------------------------------------------------+---+----------------------------------------------------------------+----------------------------------------------------------------+------------+----------------------------------------------------------------+----------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sha2, rand, concat, lit\n",
    "\n",
    "try:\n",
    "    # PII columns to hash\n",
    "    pii_columns_patients = ['name', 'address', 'phone_number', 'email']\n",
    "    \n",
    "    # Add salt to original value before hashing to enhance security\n",
    "    appointment_history_anon = appointment_history_df.select(\n",
    "        *[\n",
    "            sha2(concat(col, lit('_'), rand()), 256).alias(col) if col in pii_columns_patients \n",
    "            else col \n",
    "            for col in appointment_history_df.columns\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(\"\\nSample of anonymized patients:\")\n",
    "    appointment_history_anon.show(10, truncate=False)\n",
    "    \n",
    "    # Overwrite the original df with the hashed columns\n",
    "    appointment_history_df = appointment_history_anon\n",
    "    print(appointment_history_df.count())\n",
    "except Exception as e:\n",
    "    raise Exception(\"Error while hashing PII columns: \", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b19d403-17a6-433d-a4f1-c9caf01fcd96",
   "metadata": {},
   "source": [
    "## Step 3a: Upsert to Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0eee2d-f64c-4ac3-829c-df68abe4cabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "\n",
    "glueContext = GlueContext(spark)\n",
    "\n",
    "# Parameters\n",
    "database_name = \"your_database_name\"\n",
    "target_table = \"your_target_table\"\n",
    "\n",
    "# Step 1: Add metadata columns to `appointment_history_df`\n",
    "current_date = F.current_date()\n",
    "\n",
    "# ASSUMPTION: All incoming data is new. This will not work for historical loads or duplicates.\n",
    "appointment_history_df = appointment_history_df.withColumn(\"start_date\", current_date) \\\n",
    "                                               .withColumn(\"end_date\", F.lit(None).cast(\"date\")) \\\n",
    "                                               .withColumn(\"is_current\", F.lit(True))\n",
    "\n",
    "# Step 2: Read only relevant partitions (if partitioned by appointment_id or similar key)\n",
    "historical_dyf = glueContext.create_dynamic_frame.from_catalog(\n",
    "    database=database_name,\n",
    "    table_name=target_table,\n",
    "    push_down_predicate=\"patient_id IN ({})\".format(\n",
    "        \",\".join([str(row.appointment_id) for row in appointment_history_df.select(\"patient_id\").distinct().collect()])\n",
    "    )\n",
    ")\n",
    "\n",
    "# Convert historical DynamicFrame to DataFrame for transformations\n",
    "historical_df = historical_dyf.toDF()\n",
    "\n",
    "# Step 3: Identify rows to update\n",
    "# Compare only rows with matching appointment_id\n",
    "join_condition = [historical_df[\"patient_id\"] == appointment_history_df[\"patient_id\"]]\n",
    "updated_rows = historical_df.filter(F.col(\"is_current\") == True) \\\n",
    "    .join(appointment_history_df, join_condition, \"inner\") \\\n",
    "    .filter(\n",
    "        F.concat(*[F.col(f\"historical_df.{col}\") for col in historical_df.columns if col not in [\"start_date\", \"end_date\", \"is_current\"]]) !=\n",
    "        F.concat(*[F.col(f\"appointment_history_df.{col}\") for col in appointment_history_df.columns if col not in [\"start_date\", \"end_date\", \"is_current\"]])\n",
    "    )\n",
    "\n",
    "# Mark updated rows as inactive\n",
    "inactive_rows = updated_rows.withColumn(\"end_date\", current_date) \\\n",
    "                            .withColumn(\"is_current\", F.lit(False))\n",
    "\n",
    "# Step 4: Combine new rows and updated inactive rows\n",
    "final_df = appointment_history_df.union(inactive_rows)\n",
    "\n",
    "# Step 5: Write back to Glue table\n",
    "final_dyf = DynamicFrame.fromDF(final_df, glueContext, \"final_dyf\")\n",
    "\n",
    "glueContext.write_dynamic_frame.from_catalog(\n",
    "    frame=final_dyf,\n",
    "    database=database_name,\n",
    "    table_name=target_table,\n",
    "    additional_options={\"mergeSchema\": \"true\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eef00c-8d11-4c34-b479-2cafdc87b355",
   "metadata": {},
   "source": [
    "## Step 4: Data Storage\n",
    "- Set up LocalStack to simulate an S3 environment.\n",
    "- Store the de-identified and transformed data as Parquet files in the LocalStack S3 bucket.\n",
    "- Ensure your solution uses Docker to run the pipeline in a containerized environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff69c327-2517-49d8-ba25-142f2c945ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to LocalStack: \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Test connection to LocalStack S3 service\n",
    "url = \"http://localstack:4566\"\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Successfully connected to LocalStack:\", response.text)\n",
    "    else:\n",
    "        print(\"Failed to connect to LocalStack. Status code:\", response.status_code)\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Error connecting to LocalStack: \", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "195bf47d-1e6c-4dac-ba42-408254da4755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'my-test-bucket' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "try:\n",
    "    # Connect to LocalStack S3\n",
    "    s3 = boto3.client(\n",
    "        \"s3\",\n",
    "        endpoint_url=\"http://localstack:4566\",\n",
    "        aws_access_key_id=\"test\",\n",
    "        aws_secret_access_key=\"test\",\n",
    "        region_name=\"us-east-1\"\n",
    "    )\n",
    "    \n",
    "    # Create the bucket\n",
    "    bucket_name = \"my-test-bucket\"\n",
    "    s3.create_bucket(Bucket=bucket_name)\n",
    "    print(f\"Bucket '{bucket_name}' created successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error creating bucket:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79dca3fa-915f-4868-a031-77c810f1a3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded part-00000-cbc2d7d4-4cdd-4119-bea9-3ae3d9952cd5-c000.snappy.parquet to S3 bucket 'my-test-bucket' with key 'part-00000-cbc2d7d4-4cdd-4119-bea9-3ae3d9952cd5-c000.snappy.parquet'.\n",
      "All part files have been successfully uploaded to S3 bucket 'my-test-bucket'.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # Local directory where the files are stored\n",
    "    local_temp_path = \"/tmp/data/\"\n",
    "    \n",
    "    # Delete everything in /tmp/data/\n",
    "    if os.path.exists(local_temp_path):\n",
    "        shutil.rmtree(local_temp_path)\n",
    "    \n",
    "    # Write appointment history to tmp folder as parquet\n",
    "    appointment_history_df.write.parquet(local_temp_path, mode='overwrite')\n",
    "    \n",
    "    # Get the list of parquet part files\n",
    "    parquet_files = [f for f in os.listdir(local_temp_path) if f.endswith('.parquet')]\n",
    "    \n",
    "    # Upload each part file to S3\n",
    "    for part_file in parquet_files:\n",
    "        part_file_path = os.path.join(local_temp_path, part_file)\n",
    "    \n",
    "        # Upload the part file to S3\n",
    "        s3.upload_file(part_file_path, bucket_name, part_file)\n",
    "        print(f\"Uploaded {part_file} to S3 bucket '{bucket_name}' with key '{part_file}'.\")\n",
    "    \n",
    "    print(f\"All part files have been successfully uploaded to S3 bucket '{bucket_name}'.\")\n",
    "except Exception as e:\n",
    "    raise Exception(\"Error while uploading parquet files to LocalStack: \", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c106d1a3-a888-44dd-a287-246c0b533bd1",
   "metadata": {},
   "source": [
    "## Step 5: Data Join with PySpark\n",
    "- Use PySpark to load the two Parquet tables (patient data and appointment data) from the LocalStack S3 bucket.\n",
    "- Join the two tables on patient_id and print the resulting joined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b5bb7fa-70db-46a6-bb88-4b3a25233f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'c88c6f12-e02a-4623-959b-6edce5d0e56a', 'HostId': 's9lzHYrFp76ZVxRcpX9+5cjAnEH2ROuNkd2BHfIa6UkFVdtjf5mKR3/eTPFvsiP/XV/VLi31234=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'server': 'TwistedWeb/24.3.0', 'date': 'Sun, 01 Dec 2024 21:40:31 GMT', 'content-type': 'application/xml', 'content-length': '526', 'x-amz-request-id': 'c88c6f12-e02a-4623-959b-6edce5d0e56a', 'x-amz-id-2': 's9lzHYrFp76ZVxRcpX9+5cjAnEH2ROuNkd2BHfIa6UkFVdtjf5mKR3/eTPFvsiP/XV/VLi31234='}, 'RetryAttempts': 0}, 'IsTruncated': False, 'Contents': [{'Key': 'part-00000-cbc2d7d4-4cdd-4119-bea9-3ae3d9952cd5-c000.snappy.parquet', 'LastModified': datetime.datetime(2024, 12, 1, 21, 40, 16, tzinfo=tzlocal()), 'ETag': '\"b9ae885e055c8892052ea61a5327c842\"', 'Size': 223730, 'StorageClass': 'STANDARD'}], 'Name': 'my-test-bucket', 'Prefix': '', 'MaxKeys': 1000, 'EncodingType': 'url', 'KeyCount': 1}\n",
      "+----------+--------------------+---+--------------------+--------------------+-------------+----------------+------------------+\n",
      "|patient_id|                name|age|             address|        phone_number|    diagnosis|appointment_date|            doctor|\n",
      "+----------+--------------------+---+--------------------+--------------------+-------------+----------------+------------------+\n",
      "|         3|7a2a8e1e2dfeffb51...| 61|fcd1eeb21bb96f574...|8bbde97c44704518d...|     Diabetes|      2024-05-12|  Kristina Collins|\n",
      "|         4|bb92136a782e187f8...| 41|0e8f9ace51bf42740...|589fe6cfc3a068724...|       Asthma|      2024-08-17|     Felicia Moore|\n",
      "|         5|5670a2b43fe9008b4...| 37|a4caf19f199c9524a...|65648fb348f8a2256...|       Asthma|      2024-05-08|      Jason Taylor|\n",
      "|         5|09b5e93429a9e28b6...| 37|110d46cc23a8ce81c...|d202bf3edefe7e8ed...|       Asthma|      2024-03-20|  Eugene Wilson MD|\n",
      "|         6|21fa7cd746112aefa...| 39|b32a3ff6f68202f6f...|4377de67162a2bf49...|         None|      2024-08-23|    Jessica Martin|\n",
      "|         8|c4cb891498cf0ccd4...| 31|26e3facbd23b07510...|7aa07ff59c0ebb6e9...| Hypertension|      2024-01-18|       Erin Castro|\n",
      "|        10|125a56b1716947523...| 55|78f0d557bafa9ca80...|2f8ed63c53a16608e...| Hypertension|      2024-09-08|        Mary Ortiz|\n",
      "|        11|2b7b966e059d1ffc1...| 35|6dcfa8f48f12b295c...|abc30fd0dacd472f0...| Hypertension|      2024-04-17|Sherri Fitzpatrick|\n",
      "|        12|f575f2ebbbe124294...| 25|1a74805c5a206cc3f...|f25753ad76c82c96d...| Hypertension|      2024-07-04|         Joy Price|\n",
      "|        12|518bf2020e2862ce4...| 25|99efa8d785d7ce811...|cd04eb0c765126afb...| Hypertension|      2024-01-03|  Richard Martinez|\n",
      "|        16|02fd804ac96967dee...| 58|3b83b4d8a97c53842...|a1108fa83709a69b2...|     Diabetes|      2024-04-26|        Stacy Leon|\n",
      "|        17|ce2050417b4886f61...| 18|450371f8cff47a50f...|049237c160e74a272...|     Diabetes|      2024-07-02|  Joshua Rodriguez|\n",
      "|        17|1ca6f4bba8cd30980...| 18|3b780671809681691...|5c21757696e547a82...|     Diabetes|      2024-04-06|        Ryan Davis|\n",
      "|        17|eeb86208d9aaffb59...| 18|666dfc2187897bbae...|b726dcbf54be2a535...|     Diabetes|      2024-08-24|  Cheyenne Watkins|\n",
      "|        18|249bde61b31b36ccd...| 35|4785916c3668f52ea...|1800e0dfc5f9d64c5...|       Asthma|      2024-06-26|    Matthew Lawson|\n",
      "|        18|3890e78bd6535c486...| 35|06d6e9e2e42d7e4e3...|d29fe4f20bafa3ba9...|       Asthma|      2024-03-29|  Kristine Robbins|\n",
      "|        19|9b0c76afd7066b1f7...| 28|2c61302ebd7e6d071...|c6cddccc118b71063...|Heart Disease|      2024-01-08|      Julia Lawson|\n",
      "|        20|58d20fb6296090941...| 36|97da87891796b90cd...|15a2f66855f2aa1aa...|       Asthma|      2024-04-30|        Rose Bruce|\n",
      "|        20|73447818a0d5f96b7...| 36|12925fb7c8f82b526...|dc449a2c7871043d5...|       Asthma|      2024-03-27|       Becky Scott|\n",
      "|        21|cc5d30df04dc5eda3...| 69|fceb4cd2b98a88608...|e66a598119f05dc50...|     Diabetes|      2024-04-21|     Sonya Goodman|\n",
      "+----------+--------------------+---+--------------------+--------------------+-------------+----------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "1000\n",
      "+----------+\n",
      "|patient_id|\n",
      "+----------+\n",
      "|         3|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data is already joined, pulling down from Localstack bucket and displaying...\n",
    "\n",
    "try:\n",
    "    # List all files in the S3 bucket\n",
    "    response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "    print(response)\n",
    "    \n",
    "    # Filter the list of files to only include Parquet files\n",
    "    parquet_files = [obj['Key'] for obj in response.get('Contents', []) if obj['Key'].endswith('.parquet')]\n",
    "    \n",
    "    # Temporary directory to store the files\n",
    "    temp_dir = '/tmp/parquet_files/'\n",
    "    \n",
    "    # Delete everything in tmp\n",
    "    if os.path.exists(temp_dir):\n",
    "        shutil.rmtree(temp_dir)\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    \n",
    "    # Download each Parquet file from S3 and save it locally\n",
    "    for file_key in parquet_files:\n",
    "        # Download the file\n",
    "        file_obj = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "        file_data = file_obj['Body'].read()\n",
    "        \n",
    "        # Write the file data to a local file\n",
    "        local_path = os.path.join(temp_dir, os.path.basename(file_key))\n",
    "        with open(local_path, 'wb') as f:\n",
    "            f.write(file_data)\n",
    "    \n",
    "    # Now read all the Parquet files from the local directory into a single Spark DataFrame\n",
    "    df = spark.read.parquet(temp_dir)\n",
    "    \n",
    "    # Show the DataFrame\n",
    "    df.show()\n",
    "    print(df.count())\n",
    "    df.select(\"patient_id\").where(\"patient_id = 3\").show()\n",
    "except Exception as e:\n",
    "    raise Exception(\"Error while downloading parquet files from LocalStack: \", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602f8d34-ba18-4ccb-86d8-1209c8ebd8d4",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96c96c79-d159-468b-b8dd-dc205a4efcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Create an S3 resource pointing to LocalStack\n",
    "    s3_resource = boto3.resource(\n",
    "        's3',\n",
    "        endpoint_url='http://localstack:4566',  # LocalStack S3 endpoint\n",
    "        aws_access_key_id='test',  # Dummy credentials for LocalStack\n",
    "        aws_secret_access_key='test'\n",
    "    )\n",
    "    \n",
    "    # Reference the bucket\n",
    "    bucket = s3_resource.Bucket(bucket_name)\n",
    "    \n",
    "    # Delete all objects\n",
    "    bucket.objects.all().delete()\n",
    "    \n",
    "    # If versioning is enabled, delete all versions\n",
    "    bucket.object_versions.all().delete()\n",
    "except Exception as e:\n",
    "    raise Exception(\"Error while truncating LocalStack bucket: \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164e8c6d-5047-428a-9fa4-c739df46a5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
